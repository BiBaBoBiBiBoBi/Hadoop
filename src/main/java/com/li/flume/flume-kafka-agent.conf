kafka2hdfs.sources =kafka_source
kafka2hdfs.channels = mem_channel
kafka2hdfs.sinks = hdfs_sink
#auto.commit.enable = true
 
## kerberos config ##
#kafka2hdfs.sinks.hdfs_sink.hdfs.kerberosPrincipal = flume/datanode2.hdfs.alpha.com@OMGHADOOP.COM
#kafka2hdfs.sinks.hdfs_sink.hdfs.kerberosKeytab = /root/apache-flume-1.6.0-bin/conf/flume.keytab 
 
 
# For each one of the sources, the type is defined
kafka2hdfs.sources.kafka_source.type = org.apache.flume.source.kafka.KafkaSource
kafka2hdfs.sources.kafka_source.zookeeperConnect = 192.168.100.27:2181,192.168.100.27:2181,192.168.100.27:2181
kafka2hdfs.sources.kafka_source.topic = minivideo
#kafka2hdfs.sources.kafka_source.batchSize = 10000
kafka2hdfs.sources.kafka_source.groupId = flume4097
kafka2hdfs.sources.kafka_source.channels = mem_channel
 
 
# The channel can be defined as follows.
kafka2hdfs.sinks.hdfs_sink.type = hdfs
kafka2hdfs.sinks.hdfs_sink.hdfs.filePrefix = %Y/%m/%d/%H-kalog
kafka2hdfs.sinks.hdfs_sink.hdfs.fileSuffix =.log
kafka2hdfs.sinks.hdfs_sink.hdfs.path = hdfs://192.168.100.26:8020/flume_collect/minivideo
## roll every hour (after gz)
kafka2hdfs.sinks.hdfs_sink.hdfs.rollSize = 100000
kafka2hdfs.sinks.hdfs_sink.hdfs.rollCount = 0
kafka2hdfs.sinks.hdfs_sink.hdfs.rollInterval = 3600
kafka2hdfs.sinks.hdfs_sink.hdfs.threadsPoolSize = 300
 
 
#kafka2hdfs.sinks.hdfs_sink.hdfs.codeC = gzip
#kafka2hdfs.sinks.hdfs_sink.hdfs.fileType = CompressedStream
kafka2hdfs.sinks.hdfs_sink.hdfs.fileType=DataStream  
kafka2hdfs.sinks.hdfs_sink.hdfs.writeFormat=Text  
 
 
#Specify the channel the sink should use
kafka2hdfs.sinks.hdfs_sink.channel = mem_channel
# Each channel's type is defined.
kafka2hdfs.channels.mem_channel.type = memory
 
 
# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
kafka2hdfs.channels.mem_channel.capacity = 100
kafka2hdfs.channels.mem_channel.transactionCapacity = 100
