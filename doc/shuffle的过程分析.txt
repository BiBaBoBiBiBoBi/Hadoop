Map端：
    1、在map端首先接触的是inputsplit，在inputsplit中含有DN中的数据，每一个InputSplit都会分配一个mapper任务，mapper任务结束后产生<K,V>的输出，这些输
出先存放在缓存中，每一个map有一个环形缓存区，用于存储任务的缓存。默认大小100MB，一旦达到阈值0.8，一个后台线程就把内容写到本地磁盘中的指定目录下的新建的一
个溢出写文件。（注意：map过程的输出是写入本地磁盘而不是HDFS，但是一开始数据并不是直接写入磁盘而是缓冲在内存中，缓存的好处就是减少磁盘I/O的开销，提高合并和
排序的速度。又因为默认的内存缓冲大小是100M（当然这个是可以配置的），所以在编写map函数的时候要尽量减少内存的使用，为shuffle过程预留更多的内存，因为该过程是
最耗时的过程。）
    2、写磁盘前，要进行partition、sort和combine等操作。通过分区，将不同类型的数据分开处理，之后对不同分区的数据进行排序，如果有combiner，还要对排序后
的数据进行combine。等最后记录写完，将全部溢出文件合并为一个分区且排序的文件。（注意：在写磁盘的时候采用压缩的方式将map的输出结果进行压缩是一个减少网络开
销很有效的方法！）
    3、最后将磁盘中的数据送到reduce中，从图中可以看出map输出有三个分区，有一个分区数据被送到图示的reduce任务中，剩下的两个分区被送到其他reducer任务中。
而图示的reducer的其他的三个输入则来自其他节点的Map输出。

Reduce端：
    1、Copy阶段：Reducer通过http方式得到输出文件的分区。
    reduce端可能从n个map的结果中获取数据，而这些map的执行速度不经相同，当其中一个map运行结束时，reduce就会从RM中获取该信息。map运行结束后NM会得到消息，
进而将消息汇报给RM，reduce定时从RM获取该信息，reduce端默认有5个数据复制线程从map端复制数据。
    2、Merge阶段：如果存在多个磁盘文件会进行合并
    从map端复制来的数据首先写到reduce端的缓存中，同样缓存占用到达一定阈值会将数据写到磁盘中，同样会进行partition、combine、排序等过程。如果形成了多个
磁盘文件还会进行合并，最后合并的结果作为reduce的输入而不是写入到磁盘中。
    3、reducer
    最后将合并后的结果作为输入传入reduce任务中。（注意：当Reducer的输入文件确定后，整个Shuffle操作才最终结束。之后就是Reducer的执行了，最后Reducer会把
结果存到HDFS上。）