Hadoop 中利用 mapreduce 读写 mysql 数据
https://www.cnblogs.com/liquan-anran/p/6257161.html

shuffle的过程分析
http://www.cnblogs.com/ahu-lichang/p/6665242.html

Hadoop 2.6 MapReduce运行原理详解
https://blog.csdn.net/u011007180/article/details/52434382

Hadoop学习笔记：MapReduce框架详解
http://blog.jobbole.com/84089/


MapReduce作业(job)是客户端需要执行的一个工作单元：它包括输入数据、MapReduce程序和配置信息
Hadoop在存储有输入数据(HDFS中的数据)的节点上运行map任务，可以获得最佳性能，因为它无需使用宝贵的集群贷款资源。

java提高篇
http://cmsblogs.com/?p=41

MapReduce表连接操作之Map端join
https://blog.csdn.net/lzm1340458776/article/details/42971075

MapReduce表连接操作之Reduce端join
https://blog.csdn.net/lzm1340458776/article/details/42971485


https://blog.csdn.net/lzm1340458776/article/category/2408873/2

MapReduce实现等值连接，左外连接，右外连接，全外连接
https://blog.csdn.net/lzm1340458776/article/details/43305789


Map端join是指数据到达map处理函数之前进行合并的，效率要远远高于Reduce端join，因为Reduce端join是把所有的数据都经过Shuffle，非常消耗资源。
(1)：需要join的两个文件，一个存储在HDFS中，一个使用DistributedCache.addCacheFile()将需要join的另外一个文件加入到所有Map缓存中。
(2)：在Map函数里读取该文件，进行join
(3)：将结果输出到reduce
(4)：DistributedCache.addCacheFile()需要在作业提交前设置。


Reduce端连接比Map端连接更为普遍，因为输入的数据不需要特定的结构，但是效率比较低，因为所有数据都必须经过Shuffle过程。
(1)：Map端读取所有的文件，并在输出的内容里加上标示，代表数据是从哪个文件里来的。
(2)：在reduce处理函数中，按照标识对数据进行处理。
(3)：然后根据Key去join来求出结果直接输出。
