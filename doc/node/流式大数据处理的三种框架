Strom
    先要设计一个用于流式计算的图结构，一个拓扑图。拓扑图会被提交给集群，由集群的主控节点将代码分发，将任务分配给各个工作节点。一个拓扑中包括spout和bolt两种角色，其中spout发送消息，负责将接收到的数据量
    以元组的形式发送出去；bolt负责转换这些数据流，在bolt中可以完成计算、过滤等操作，bolt自身也可以随机将数据发送给其他bolt。spout发射出的tuple是不可变数据，对应固定的键值对。
spark streaming
   是spark一个扩张，它不想storm那样一次一个地处理数据流，而是在处理前按时间间隔预先将其切分为一段一段的批处理作业。spark针对持续性数据流的抽象成为DStream，一个DStream是一个微批处理的RDD；而RDD则是一
   钟分布式数据集，能够以两种方式并行运作，分别是任意函数和滑动窗口数据的转换
flink
    是一个针对流数据和批处理的分布式处理引擎。对flink而言，其所有处理的主要场景就是流数据，批数据只是流数据的一个极限特例，flink会把所有任务当成流来处理。